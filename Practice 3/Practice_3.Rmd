---
title: "Practice Problems 3"
author: "Jordan Lian"
date: "2/14/2021"
output:
  pdf_document: default
  html_document: default
urlcolor: blue
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

1. Download the [data set for the tutorial](https://da5030.weebly.com/uploads/8/6/5/9/8659576/prostate_cancer.csv).
```{r origin_prostate, prostate, warning=FALSE}
library(tidyverse)
origin_prostate <- read.csv("prostate_cancer.csv", stringsAsFactors = FALSE)
prostate <- origin_prostate
head(prostate)
```

2. Follow this [tutorial on applying kNN to prostate cancer detection](https://www.analyticsvidhya.com/blog/2015/08/learning-concept-knn-algorithms-programming/) and implement all of the steps in an R Notebook. Make sure to explain each step and what it does. (*Note*: The data set provided as part of this assignment has been slightly modified from the one used in the tutorial, so small deviations in the result can be expected.)'

### Step 1: Data Collection
See Question 1

### Step 2: Preparing and Exploring the Data
```{r warning=FALSE}
# remove the first variable (id) from the dataset 
prostate <- prostate[-1]

# get table of number of patients based on diagnosis
table(prostate$diagnosis_result)

# Rename B and M to Benign and Malignant
prostate$diagnosis <- factor(prostate$diagnosis_result, levels = c("B", "M"), 
                             labels = c("Benign", "Malignant"))
# Get percentage of B/M diagnoses
round(prop.table(table(prostate$diagnosis)) * 100, digits = 1)
```

### Normalize Numeric Data
```{r normalize, norm_prostate, warning=FALSE}
normalize <- function(x) {
  return ((x - min(x)) / (max(x) - min(x))) }
norm_prostate <- as.data.frame(lapply(prostate[2:9], normalize))
summary(norm_prostate$radius)
```

### Create test and training data set
```{r prostate_train, prostate_test, train_labels, test_labels, warning=FALSE}
# Split training and test dataset by 65/35
prostate_train <- norm_prostate[1:65,]
prostate_test <- norm_prostate[66:100,]

# Target variable is 'diagnosis_result', which is not in the training/test datasets
train_labels <- prostate[1:65, 1]
test_labels <- prostate[66:100, 1]
```

### Step 3 - Train the model on data
```{r prc_test_pred, warning=FALSE}
library(class)
prc_test_pred <- knn(train = prostate_train, 
                     test = prostate_test, 
                     cl = train_labels, 
                     k=10)
```

### Step 4 - Evaluate the model performance
```{r warning=FALSE}
library(gmodels)
CrossTable(x = test_labels, y = prc_test_pred, prop.chisq = FALSE)
```  

### Step 5 - Improve the performance of the model, change the k-value
```{r warning=FALSE}
# k=8
prc_test_pred <- knn(train = prostate_train, 
                     test = prostate_test, 
                     cl = train_labels, 
                     k = 8)
CrossTable(x = test_labels, y = prc_test_pred, prop.chisq = FALSE)

# k=9
prc_test_pred <- knn(train = prostate_train, 
                     test = prostate_test, 
                     cl = train_labels, 
                     k = 9)
CrossTable(x = test_labels, y = prc_test_pred, prop.chisq = FALSE)

# k=11
prc_test_pred <- knn(train = prostate_train, 
                     test = prostate_test, 
                     cl = train_labels, 
                     k = 11)
CrossTable(x = test_labels, y = prc_test_pred, prop.chisq = FALSE)

# k=12
prc_test_pred <- knn(train = prostate_train, 
                     test = prostate_test, 
                     cl = train_labels, 
                     k = 12)
CrossTable(x = test_labels, y = prc_test_pred, prop.chisq = FALSE)
```

k=9 produced the least amount of false positives and most accurate results overall, so I would use k=9 for kNN for this dataset. 

3. Once you have complete the tutorial, try another kNN implementation from another package, such as the **caret** package. Compare the accuracy of the two implementations.'
```{r warning=FALSE}
library(caret)
```

### Sampling
```{r indxTrain, training, testing, warning=FALSE}
# Split data as training and test set. Using createDataPartition() function from caret
indxTrain <- createDataPartition(y = prostate$diagnosis_result,p = 0.75,list = FALSE)
training <- prostate[indxTrain,]
testing <- prostate[-indxTrain,]

# Check distibution in original data and partitioned data
prop.table(table(prostate$diagnosis_result)) * 100
prop.table(table(testing$diagnosis_result)) * 100
prop.table(table(prostate$diagnosis_result)) * 100
```  

### Preprocessing
```{r trainX, preProcValues, warning=FALSE}
trainX <- training[,names(training) != "diagnosis_result"]
preProcValues <- preProcess(x = trainX, method = c("center", "scale"))
preProcValues
```

### Training and train control
```{r ctrl, knnFit, warning=FALSE}
set.seed(400)
ctrl <- trainControl(method="repeatedcv", repeats = 3)
knnFit <- train(diagnosis_result ~ ., 
                data = training, 
                method = "knn", 
                trControl = ctrl, 
                preProcess = c("center","scale"), 
                tuneLength = 20)

# kNNFit output
knnFit

#Plot yields Number of Neighbors Vs accuracy (based on repeated cross validation)
plot(knnFit)
```

4. Try the *confusionMatrix* function from the **caret** package to determine the accuracy of both algorithms.
```{r knnPredict, ctrl, knnFit, warning=FALSE}
knnPredict <- predict(knnFit, newdata = testing)
    
# Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(knnPredict, as.factor(testing$diagnosis_result))
mean(knnPredict == testing$diagnosis_result)

# Verify 2 class summary function
ctrl <- trainControl(method="repeatedcv", 
                     repeats = 3,
                     classProbs = TRUE, 
                     summaryFunction = twoClassSummary)
knnFit <- train(diagnosis_result ~ ., 
                data = training, 
                method = "knn", 
                trControl = ctrl, 
                preProcess = c("center","scale"), 
                tuneLength = 20)

knnFit    
plot(knnFit, print.thres = 0.5, type="S")
knnPredict <- predict(knnFit,newdata = testing)

# Get the confusion matrix to see accuracy value and other parameter values
confusionMatrix(knnPredict, as.factor(testing$diagnosis_result))
mean(knnPredict == testing$diagnosis_result) 
```